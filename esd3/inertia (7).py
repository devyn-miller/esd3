# # -*- coding: utf-8 -*-
# """Inertia.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1rlvk1tm_0GRXyN3ITXKZXdktwqjJb0y2
# """

# # Commented out IPython magic to ensure Python compatibility.
# # %pip install ray
# # %pip install gymnasium

# """# Libraries"""

# import gymnasium as gym
# from gymnasium import spaces, vector
# import ray
# from ray.rllib.env.multi_agent_env import MultiAgentEnv
# import numpy as np
# import csv
# import random
# import logging

# """# Parameters"""

# CUSTOMERS = 3000
# PERIODS = 100
# STARTING_PRICES = [300,300,300]
# LARGEST_PRICE = 1000 # most you can decrease your prices in one period
# SMALLEST_PRICE = 0 # most you can increase your prices in one period


# def calculate_market_share(prices, inertia_factor=0.75, price_sensitivity_mean=0.2, price_sensitivity_std=0.05, smoothing_factor=0.05, total_customers=1000):
#     """
#     Calculate the market shares of firms based on prices, adjusting for customer inertia, smoothing,
#     and RL-ready optimization with variable price sensitivity modeled by a normal distribution.

#     Parameters:
#     prices (list): A list of prices for each firm.
#     inertia_factor (float): Proportion of customers resistant to switching (default 0.75).
#     price_sensitivity_mean (float): Mean sensitivity of customers to price differences.
#     price_sensitivity_std (float): Standard deviation for sensitivity to price differences.
#     smoothing_factor (float): A small factor to smooth price differences, preventing over-reactions to
#                               small price changes (default 0.05).
#     total_customers (int): The total number of customers in the market (default 1000).

#     Returns:
#     List: A list representing the number of customers each firm will have.
#     """

#     # Number of firms
#     num_firms = len(prices)

#     # Normalize prices: this ensures prices are comparable on a relative scale
#     min_price = np.min(prices)
#     max_price = np.max(prices)
#     normalized_prices = (prices - min_price) / (max_price - min_price + smoothing_factor)  # Add smoothing to avoid division by zero

#     # Initialize market shares
#     market_shares = np.zeros(num_firms)

#     # Generate price sensitivities for each customer based on a normal distribution
#     price_sensitivities = np.random.normal(price_sensitivity_mean, price_sensitivity_std, total_customers)
#     price_sensitivities = np.clip(price_sensitivities, 0, 1)  # Ensure sensitivities are within [0, 1]

#     # Calculate the relative attractiveness of each firm for each customer based on variable price sensitivity
#     for i in range(num_firms):
#         # Each customer has a different price sensitivity affecting their attractiveness to each firm
#         attractiveness = 1 - price_sensitivities * normalized_prices[i]

#         # Combine inertia and attractiveness
#         market_shares[i] = (1 - inertia_factor) * np.mean(attractiveness) + inertia_factor / num_firms

#     # Ensure the market shares sum to 1 by normalizing the shares
#     market_shares = market_shares / np.sum(market_shares)

#     # Scale market shares by the total number of customers
#     market_shares = market_shares * total_customers

#     # Apply final rounding for integer customer numbers
#     rounded_shares = np.round(market_shares).astype(int)

#     # Adjust rounding: ensure the total number of customers is preserved after rounding
#     difference = total_customers - np.sum(rounded_shares)
#     if difference != 0:
#         # Randomly adjust shares to account for rounding difference
#         indices = np.random.choice(num_firms, abs(difference), replace=False)
#         adjustment = 1 if difference > 0 else -1
#         for index in indices:
#             rounded_shares[index] += adjustment

#     market_shares = rounded_shares.tolist()
#     return market_shares


# print(calculate_market_share(STARTING_PRICES))

# class InertiaEnv(MultiAgentEnv):
#     def __init__(self, seed=None, checkpoint_periods=[0, 5, 10]):
#         super(InertiaEnv, self).__init__()
#         self.checkpoint_periods = checkpoint_periods
#         self.checkpoint_results = {period: [] for period in checkpoint_periods}
#         #logging.basicConfig(level=logging.DEBUG)
#         self.t_steps = 0
#         self._num_agents = len(STARTING_PRICES)
#         self.agents = [f'agent_{i}' for i in range(self._num_agents)]

#         self.action_space = spaces.Dict({
#             agent: spaces.Box(low=SMALLEST_PRICE,high=LARGEST_PRICE,dtype=np.int32)
#             for agent in self.agents
#         })

#         self.observation_space = spaces.Dict({
#                 agent: spaces.Dict({'price': spaces.Box(low=SMALLEST_PRICE, high=LARGEST_PRICE,dtype=np.int32),
#                                     'market_prices': spaces.Box(low=0, high=LARGEST_PRICE,  shape=(len(STARTING_PRICES),), dtype=np.int32),
#                                     'market_quantities' :spaces.Box(low=0, high=np.inf,  shape=(len(STARTING_PRICES),) ,dtype=np.int32),
#                                              })
#                 for agent in self.agents
#             })
#         self.reset()

#     def step(self,actions):
#         self.t_steps += 1
#         self.current_period += 1
#         obs = {}
#         rewards = {}
#         terminateds = {}
#         truncateds = {}
#         info = {}
#         prices = [0 for i in range(len(actions))]
#         for i,(agent_id,action) in enumerate(actions.items()):
#             rewards[agent_id] = 0
#             truncateds[agent_id] = False
#             terminateds[agent_id] = False
#             prices[i] = action[0]

#         # Calculate market shares with all parameter combinations at checkpoints
#         if self.current_period in self.checkpoint_periods:
#             checkpoint_results = test_parameter_combinations(prices)
#             self.checkpoint_results[self.current_period] = checkpoint_results

#         # This formula will be updated with the mathematical model generated from lit review
#         self.quantities = [i for i in calculate_market_share(prices)]
#         self.prices = prices

#         for i,(agent_id,action) in enumerate(actions.items()):
#             rewards[agent_id] += int(self.quantities[i]*prices[i])



#         truncateds['__all__'] = all(truncateds.values())

#         if self.current_period>PERIODS:
#             for agent_id, state in actions.items():
#                 terminateds[agent_id] = True
#             terminateds['__all__'] = all(terminateds.values())


#         for i,(agent_id, action) in enumerate(actions.items()):
#             obs[agent_id] = self._get_obs(i)
#         terminateds['__all__'] = all(terminateds.values())

#         return obs,rewards,terminateds,truncateds,info

#     def reset(self,*, seed=None, options=None):
#         self.current_period = 0
#         self.prices = STARTING_PRICES.copy()
#         self.quantities =calculate_market_share(STARTING_PRICES)
#         self.states = {
#             agent_id: {
#                 'price': STARTING_PRICES[i],
#                 'market_prices': np.array(STARTING_PRICES),
#                 'market_quantities': np.array(calculate_market_share(STARTING_PRICES))
#             }
#             for i,agent_id in enumerate(self.agents)
#         }
#         obs = {}
#         for i,agent_id in enumerate(self.agents):
#             obs[agent_id] = self._get_obs(i)

#         return obs, {}

#     def _get_obs(self,agent_id):
#         obs = {
#                 'price': np.array([self.prices[agent_id]],dtype=np.int32),
#                 'market_prices': np.array(self.prices,dtype=np.int32),
#                 'market_quantities': np.array(self.quantities,dtype=np.int32)
#             }
#         return obs

# def display_checkpoint_results(env):
#     """Display the results from all checkpoints in a organized format."""
#     for period in env.checkpoint_periods:
#         print(f"\n=== Results for Period {period} ===")
#         results = env.checkpoint_results[period]
#         for result in results:
#             print(f"\nParameters:")
#             print(f"  Inertia Factor: {result['inertia']}")
#             print(f"  Price Sensitivity Mean: {result['sensitivity_mean']}")
#             print(f"  Price Sensitivity Std: {result['sensitivity_std']}")
#             print(f"  Smoothing Factor: {result['smoothing']}")
#             print(f"  Market Shares: {result['market_shares']}")

# env = InertiaEnv()
# obs, info = env.reset()

# # Run for 11 periods to capture checkpoint at period 10
# for i in range(11):
#     actions = {agent_id: env.action_space[agent_id].sample() for agent_id in env.agents}
#     obs, rewards, terminateds, truncateds, info = env.step(actions)
    
# # Display results from all checkpoints
# display_checkpoint_results(env)

# # Parameter configurations
# inertia_factors = [0.65, 0.75, 0.85]
# price_sensitivity_means = [0.2, 0.3]
# price_sensitivity_stds = [0.01, 0.05]
# smoothing_factors = [0.01, 0.05]

# # Function to test all parameter combinations at specific checkpoints
# def test_parameter_combinations(prices, checkpoints=[0, 5, 10]):
#     results = []
    
#     for inertia in inertia_factors:
#         for ps_mean in price_sensitivity_means:
#             for ps_std in price_sensitivity_stds:
#                 for smooth in smoothing_factors:
#                     # Calculate market shares for this parameter combination
#                     market_shares = calculate_market_share(
#                         prices,
#                         inertia_factor=inertia,
#                         price_sensitivity_mean=ps_mean,
#                         price_sensitivity_std=ps_std,
#                         smoothing_factor=smooth,
#                         total_customers=CUSTOMERS
#                     )
                    
#                     # Store results with parameter values
#                     results.append({
#                         'inertia': inertia,
#                         'sensitivity_mean': ps_mean,
#                         'sensitivity_std': ps_std,
#                         'smoothing': smooth,
#                         'market_shares': market_shares
#                     })
    
#     return results

# # Test initial configuration
# print("\nTesting all parameter combinations for starting prices:")
# initial_results = test_parameter_combinations(STARTING_PRICES)
# for result in initial_results:
#     print(f"\nParameters: inertia={result['inertia']}, sensitivity_mean={result['sensitivity_mean']}, "
#           f"sensitivity_std={result['sensitivity_std']}, smoothing={result['smoothing']}")
#     print(f"Market shares: {result['market_shares']}")

# """# Training"""

# if ray.is_initialized():
#   ray.shutdown()
# ray.init(ignore_reinit_error=True)

# ray.available_resources()

# import os
# print(os.getcwd())
# save_dir = os.getcwd()

# from ray import air, tune
# from ray.rllib.algorithms.ppo import PPOConfig


# from ray.rllib.models import ModelCatalog
# from ray.rllib.policy.policy import PolicySpec
# from ray.rllib.utils.framework import try_import_tf
# from ray.rllib.utils.test_utils import check_learning_achieved
# from functools import partial

# num_policies = 3 # each agent will have its own policy
# timesteps_total = 1000 #1000000
# max_training_iteration = 10000
# num_agents = 3


# agent_ids = InertiaEnv().agents
# sym_policies = {agent_id: f"policy_agent_0" for agent_id in agent_ids}  # Symmetric
# asym_policies = {agent_id: f"policy_{agent_id}" for agent_id in agent_ids}  # Asymmetric
# def policy_mapping_fn(agent_id, episode, worker, *, policies=None, **kwargs):
#     return policies[agent_id]


# policies = asym_policies
# policy_mapping = partial(policy_mapping_fn, policies=policies)


# env = InertiaEnv()
# data = []
# # for price in [j*5 for j in range(200)]:
# mean_reward = 0
# for i in range(100):
#     obs, info = env.reset()
#     terminated = {agent_id:False for agent_id in agent_ids}
#     terminated["__all__"] = False
#     steps = 0
#     while not terminated["__all__"]:
#         actions = {}
#         for agent in agent_ids:
#             a = algo.compute_single_action(
#                 observation=obs[agent],
#                 policy_id=policies[agent],
#             )
#             actions[agent] = a
#         # actions['agent_0'] = [price]
#         prev_obs = obs
#         obs, reward, terminated, truncated, info = env.step(actions)
#         steps += 1
#         data.append([obs['agent_0']['market_prices'],obs['agent_0']['market_quantities'],[r/1000 for r in reward.values()]])
#         # mean_reward += reward

# # Done: Prices all three firms, Customers (%) allocated by period, full profit data

# data

# # Commented out IPython magic to ensure Python compatibility.
# # %load_ext tensorboard
# # %tensorboard --logdir=save_dir

# from tensorboard import program

# # Path to the directory containing the TensorBoard logs
# logdir = save_dir

# # Start TensorBoard program
# tb = program.TensorBoard()
# tb.configure(argv=[None, '--logdir', logdir, '--port', str(6007)])
# url = tb.launch()
# print(f"TensorBoard started at {url}")